{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzSUkorHnkUq99yPH5adEe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAAXkZkuYLSv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import timm\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "import time\n",
        "from huggingface_hub import login\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define dataset path\n",
        "data_dir = './train'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset = ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "test_size = int(0.2 * len(dataset))  # 20% for testing\n",
        "train_val_size = len(dataset) - test_size  # Remaining 80% for training & validation\n",
        "\n",
        "train_val_dataset, test_dataset = random_split(dataset, [train_val_size, test_size])\n",
        "\n",
        "val_size = int(0.2 * train_val_size)\n",
        "train_size = train_val_size - val_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=32, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=32, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=32, pin_memory=True)\n",
        "\n",
        "print(f\"Dataset split: {len(train_dataset)} training, {len(val_dataset)} validation, {len(test_dataset)} testing.\")\n",
        "\n",
        "# Define models\n",
        "model_names = [\"convnext_tiny\", \"deit_tiny_patch16_224\", \"mobilenetv3_large_100\", \"resnet50\", \"swin_tiny_patch4_window7_224\", \"vgg19_bn\", \"efficientnet_b3\"]\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, val_loader, optimizer, epochs=12):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        train_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.float().to(device)\n",
        "            labels = labels.view(-1, 1)  # Reshape for BCE Loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)  # Keep [batch_size, 1]\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.float().to(device)\n",
        "                labels = labels.view(-1, 1)\n",
        "\n",
        "                outputs = model(images)  # Keep [batch_size, 1]\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        val_acc = correct / total\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_duration = end_time - start_time  # Calculate time taken\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss/len(train_loader):.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f} | Time: {epoch_duration:.2f} sec\")\n",
        "\n",
        "# Loop through models\n",
        "for model_name in model_names:\n",
        "    print(f\"\\nTraining {model_name}...\\n\")\n",
        "\n",
        "    model = timm.create_model(model_name, pretrained=True, num_classes=1)  # Binary classification\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Train the model\n",
        "    train_model(model, train_loader, val_loader, optimizer = optim.Adam(model.parameters(), lr=0.0001), epochs=25)\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(model.state_dict(), f\"{model_name}_classifier.pth\")\n",
        "    print(f\"Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def test_model_with_confusion_matrix(model, test_loader):\n",
        "    model.eval()\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    test_loss, correct, total = 0.0, 0, 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.float().to(device)\n",
        "            labels = labels.view(-1, 1)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy().flatten())\n",
        "            all_preds.extend(predicted.cpu().numpy().flatten())\n",
        "\n",
        "    test_acc = correct / total\n",
        "    print(f\"Test Loss: {test_loss/len(test_loader):.4f} | Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Compute Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Plot Confusion Matrix\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=[\"Illegal\", \"Legal\"], yticklabels=[\"Illegal\", \"Legal\"])\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=[\"Illegal\", \"Legal\"]))\n",
        "\n",
        "# Run the test function\n",
        "test_model_with_confusion_matrix(model, test_loader)"
      ],
      "metadata": {
        "id": "FEAX773mYXSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# model_name = \"resnet50\"\n",
        "# model = timm.create_model(model_name, pretrained=True, num_classes=1)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# Image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize for model input\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load and transform image\n",
        "image_path = \"/home/train/aug_legal_folder/aug_0_3000.png\"\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Hook to store gradients and activations\n",
        "gradients = None\n",
        "activations = None\n",
        "\n",
        "def save_gradients(grad):\n",
        "    global gradients\n",
        "    gradients = grad\n",
        "\n",
        "# Find the last convolutional layer dynamically\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, torch.nn.Conv2d):\n",
        "        target_layer = module  # Last Conv layer\n",
        "\n",
        "# Forward hook to get activations\n",
        "def forward_hook(module, input, output):\n",
        "    global activations\n",
        "    activations = output\n",
        "\n",
        "# Register hooks\n",
        "target_layer.register_forward_hook(forward_hook)\n",
        "target_layer.register_full_backward_hook(lambda module, grad_in, grad_out: save_gradients(grad_out[0]))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)  # Move model to the appropriate device\n",
        "input_tensor = input_tensor.to(device)  # Move input tensor to the same device\n",
        "\n",
        "# Forward pass\n",
        "output = model(input_tensor)\n",
        "\n",
        "# Compute gradients w.r.t. highest logit\n",
        "target_class = (output > 0.5).float().item()  # Binary threshold\n",
        "model.zero_grad()\n",
        "output.backward(torch.tensor([[1.0]], device=device))\n",
        "\n",
        "# Compute Grad-CAM\n",
        "weights = gradients.mean(dim=(2, 3), keepdim=True)  # Global average pooling of gradients\n",
        "gradcam = torch.relu((weights * activations).sum(dim=1)).squeeze().cpu().detach().numpy()\n",
        "\n",
        "# Normalize and convert to heatmap\n",
        "gradcam = cv2.resize(gradcam, (224, 224))\n",
        "gradcam = (gradcam - gradcam.min()) / (gradcam.max() - gradcam.min())\n",
        "heatmap = cv2.applyColorMap(np.uint8(255 * gradcam), cv2.COLORMAP_JET)\n",
        "\n",
        "# Overlay on original image\n",
        "image_np = np.array(image.resize((224, 224)))\n",
        "overlay = cv2.addWeighted(image_np, 0.5, heatmap, 0.5, 0)\n",
        "\n",
        "# Show results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(image_np)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(gradcam, cmap=\"jet\")\n",
        "plt.title(\"Grad-CAM Heatmap\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(overlay)\n",
        "plt.title(\"Overlay\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E5Ys8josYZam"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}